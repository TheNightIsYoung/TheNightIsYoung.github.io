<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>TensorFlow GPU 支持: Ubuntu16.04 + Nvidia GTX + CUDA + CUDNN - When Art Meets Tech</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="When Art Meets Tech"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="When Art Meets Tech"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="Update：之前为了 TensorFlow 学习使用配置的 TensorFlow 深度学习环境（CPU Support）计算性能较差，已经不再适合现阶段学习开发使用了。故最近准备升级一下深度学习服务器，重新配置支持 GPU 显卡加速计算的 TensorFlow 深度学习开发环境。"><meta property="og:type" content="blog"><meta property="og:title" content="TensorFlow GPU 支持: Ubuntu16.04 + Nvidia GTX + CUDA + CUDNN"><meta property="og:url" content="https://www.orangeshare.cn/2018/04/02/tensorflow-gpu-zhi-chi-ubuntu16-04-nvidia-gtx-cuda-cudnn/"><meta property="og:site_name" content="When Art Meets Tech"><meta property="og:description" content="Update：之前为了 TensorFlow 学习使用配置的 TensorFlow 深度学习环境（CPU Support）计算性能较差，已经不再适合现阶段学习开发使用了。故最近准备升级一下深度学习服务器，重新配置支持 GPU 显卡加速计算的 TensorFlow 深度学习开发环境。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://s2.loli.net/2023/04/02/djgq2XLsfFt9DeZ.webp"><meta property="og:image" content="https://s2.loli.net/2023/04/02/mxd8tSh7gwKqp3r.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/Y1FzqJ4eNxuQTBG.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/dwj1zT6emRhNLDQ.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/2avlsfpF3nkPBeG.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/dEUTc5KYfqop7ZB.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/BQp9SZYzCXIHlv4.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/2X6bkeIilrGawN3.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/n9oMAYvPcugHUKk.png"><meta property="og:image" content="https://s2.loli.net/2023/04/02/TYJGrdqMLfxcI83.png"><meta property="article:published_time" content="2018-04-02T00:08:38.000Z"><meta property="article:modified_time" content="2023-04-03T01:27:21.788Z"><meta property="article:author" content="Waldeinsamkeit"><meta property="article:tag" content="TensorFlow"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://s2.loli.net/2023/04/02/djgq2XLsfFt9DeZ.webp"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.orangeshare.cn/2018/04/02/tensorflow-gpu-zhi-chi-ubuntu16-04-nvidia-gtx-cuda-cudnn/"},"headline":"When Art Meets Tech","image":["https://s2.loli.net/2023/04/02/mxd8tSh7gwKqp3r.png","https://s2.loli.net/2023/04/02/Y1FzqJ4eNxuQTBG.png","https://s2.loli.net/2023/04/02/dwj1zT6emRhNLDQ.png","https://s2.loli.net/2023/04/02/2avlsfpF3nkPBeG.png","https://s2.loli.net/2023/04/02/dEUTc5KYfqop7ZB.png","https://s2.loli.net/2023/04/02/BQp9SZYzCXIHlv4.png","https://s2.loli.net/2023/04/02/2X6bkeIilrGawN3.png","https://s2.loli.net/2023/04/02/n9oMAYvPcugHUKk.png","https://s2.loli.net/2023/04/02/TYJGrdqMLfxcI83.png"],"datePublished":"2018-04-02T00:08:38.000Z","dateModified":"2023-04-03T01:27:21.788Z","author":{"@type":"Person","name":"Waldeinsamkeit"},"description":"Update：之前为了 TensorFlow 学习使用配置的 TensorFlow 深度学习环境（CPU Support）计算性能较差，已经不再适合现阶段学习开发使用了。故最近准备升级一下深度学习服务器，重新配置支持 GPU 显卡加速计算的 TensorFlow 深度学习开发环境。"}</script><link rel="canonical" href="https://www.orangeshare.cn/2018/04/02/tensorflow-gpu-zhi-chi-ubuntu16-04-nvidia-gtx-cuda-cudnn/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.2.0"></head>    <body class="is-3-column">    <nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="When Art Meets Tech" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Hexo Search" href="https://hexo.io/zh-cn/"><i class="fab fa-hotjar"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>TensorFlow GPU 支持: Ubuntu16.04 + Nvidia GTX + CUDA + CUDNN</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2018-04-02</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2023-04-03</time></span><span class="level-item"><a class="link-muted" href="/categories/DeepLearning/">DeepLearning</a></span><span class="level-item">an hour read (About 11262 words)</span></div></div><div class="content"><p>Update：之前为了 TensorFlow 学习使用配置的 TensorFlow 深度学习环境（CPU Support）计算性能较差，已经不再适合现阶段学习开发使用了。故最近准备升级一下深度学习服务器，重新配置支持 GPU 显卡加速计算的 TensorFlow 深度学习开发环境。</p>
<a id="more"></a>

<p>配置过程中参考了网络上很多的相关博文，也遇到过很多坑，为了感谢配置过程中各位大佬的帮助以及方便本人下次配置或者升级，整理以作此文。</p>
<p><font color="green">更多 TensorFlow 框架搭建相关内容，请关注博主相关博文系列 ↓↓↓↓↓</font></p>
<p>之一 &gt;&gt;&gt;&gt; <a href="https://www.orangeshare.cn/2018/04/01/yi-wen-xiang-jie-quan-ping-tai-tensorflow-shen-du-xue-xi-kuang-jia-zai-xian-da-jian-cpu-gpu-zhi-chi/">一文详解全平台 TensorFlow 深度学习框架在线搭建 (CPU&amp;GPU 支持)</a></p>
<p>之二 &gt;&gt;&gt;&gt; <a href="https://www.orangeshare.cn/2018/04/02/tensorflow-gpu-zhi-chi-ubuntu16-04-nvidia-gtx-cuda-cudnn/">TensorFlow GPU 支持: Ubuntu16.04 + Nvidia GTX + CUDA + CUDNN</a></p>
<hr>
<h2 id="Before-Reading"><a href="#Before-Reading" class="headerlink" title="Before Reading"></a>Before Reading</h2><p>TensorFlow GPU Support 配置须知：</p>
<h3 id="服务器硬件要求"><a href="#服务器硬件要求" class="headerlink" title="服务器硬件要求"></a>服务器硬件要求</h3><p><font color="red">↓↓↓↓↓↓ 关于 内存（Memory）↓↓↓↓↓↓</font></p>
<p>16GB 以上。</p>
<p>推荐：条件允许，尽可能大一点。</p>
<p><font color="red">↓↓↓↓↓↓ 关于 CPU ↓↓↓↓↓↓</font></p>
<p>不同于 TensorFlow For CPU Support 深度学习环境的搭建，GPU Support 环境主要使用 GPU 独立显卡进行计算加速，CPU 的核心数并不重要，只要拥有相对较高的主频就可以，因此对 CPU 的要求其实并不是很高。</p>
<p>推荐：具体根据实际情况进行选择，有条件的可以选择性能更好一点的，可以更好的兼容 TensorFlow For GPU Support 环境。</p>
<p><font color="red">↓↓↓↓↓↓ 关于 GPU ↓↓↓↓↓↓</font></p>
<p>独立显卡是主角，TensorFlow For GPU Support 深度学习环境的核心计算都是依托于 GPU 进行运算的，故独立显卡的性能直接影响深度学习环境计算能力！！！</p>
<p>👇👇👇 <strong>并不是所有类型的独立显卡（GPU）都可以支持搭建 TensorFlow 深度学习环境</strong> 👇👇👇</p>
<p>我们需要能够 <font color="green">支持 CUDA 平台（一种由 NVIDIA 推出的通用并行计算架构）</font>的 GPU 才行，故常见的深度学习独立显卡都选择【NVIDIA 显卡（也就是我们常说的 <strong>N 卡</strong>）】。</p>
<p>实际上，也并不是所有的 NVIDIA 显卡都支持此功能，NVIDIA 官方提供了 &gt;&gt;&gt;&gt; 【<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus">不同显卡系列的支持列表查询</a>】 &lt;&lt;&lt;&lt; 同时你可以查看到相应 GPU 的计算能力。</p>
<p>如果你手头刚好有一块在支持列表内的独立显卡，那么恭喜你可以跳过本小节下面的内容开始后续的教程了~~~</p>
<p>| ============================================ <strong>选购性价比 GPU？</strong> =============================================== |</p>
<p>如果你想要选购一块成本效益最佳的 GPU，推荐参考 Tim Dettmers 博客给出的 &gt;&gt;&gt;&gt; 【<a target="_blank" rel="noopener" href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">NVIDIA 卡分析与推荐–持续更新</a>】 &lt;&lt;&lt;&lt; Tim Dettmers`s Experience and Advice for Using GPUs in Deep Learning。</p>
<p>这里给出博主测试出的主流显卡成本效益图，可供你参考选择：</p>
<p><img src="https://s2.loli.net/2023/04/02/djgq2XLsfFt9DeZ.webp"></p>
<p>本文我是基于手头现有的最好的设备进行搭建的，争取早日攒一台更好的服务器出来~~~</p>
<hr>
<h3 id="你应该了解你的-GPU"><a href="#你应该了解你的-GPU" class="headerlink" title="你应该了解你的 GPU"></a>你应该了解你的 GPU</h3><p>这里，你应该已经有了一块可以使用的 GPU 了。但在搭建基于 GPU 显卡加速运算的 TensorFlow【TensorFlow For GPU Support】深度学习环境之前，你首先应该做的就是：</p>
<p>先明确预使用的独立显卡（GPU ）的详细信息（包括显卡型号、显存、计算性能等等）。</p>
<p>这是因为，TensorFlow 不仅对显卡类型（支持 CUDA）有要求，而且有些 TensorFlow 模型需要较大的 GPU 内存，或更多的 GPU 计算核心（即更强的计算能力，加速模型运算），了解预搭载独立显卡（GPU）的详细信息可以更好的帮助我们使用 GPU 进行 TensorFlow 计算加速。</p>
<hr>
<h3 id="CUDA-amp-amp-CUDNN-amp-amp-TF"><a href="#CUDA-amp-amp-CUDNN-amp-amp-TF" class="headerlink" title="CUDA &amp;&amp; CUDNN &amp;&amp; TF"></a>CUDA &amp;&amp; CUDNN &amp;&amp; TF</h3><p>TensorFlow 要想使用 GPU 进行计算加速（相较于 CPU），那么就必须部署 CUDA 和 CUDNN。</p>
<p>👇👇👇 先了解一下什么是 <strong>CUDA</strong> &amp;&amp; <strong>CUDNN</strong> ？ 👇👇👇</p>
<p><strong>CUDA</strong> &gt;&gt;&gt;&gt; 显卡厂商 NVIDIA 推出的通用并行计算平台，它使得 GPU 能够解决并行的、复杂的计算问题。</p>
<p><strong>CUDNN（ cuDNN）</strong> &gt;&gt;&gt;&gt; CUDA DNN 的缩写，它是 CUDA 平台深度神经网络的计算库。想要在 CUDA 上运行深度神经网络，就要安装 cuDNN。</p>
<p><font color="red">↓↓↓↓↓↓ 这里，需要注意一个问题（很重要）↓↓↓↓↓↓</font></p>
<p>我们知道 TensorFlow 提供有丰富的版本支持，但 <strong>某一版本的 TensorFlow 只兼容特定版本的 CUDA 和 CUDNN。</strong>也就是说，我们选择安装的显卡并行计算平台（CUDA）、深度神经网络 GPU 计算库（CUDNN）以及 TensorFlow 的版本要相互兼容。</p>
<p><font color="red">↓↓↓↓↓↓ 关于 CUDA &amp;&amp; CuDNN &amp;&amp; TensorFlow 版本的选择问题 ↓↓↓↓↓↓</font></p>
<p>可以根据官方实测过的【<font color="green">Tensorflow &amp;&amp; NVIDIA 版本信息对照表</font>】进行选择，如下：</p>
<p>[1] &gt;&gt;&gt;&gt; For Linux/macOS &gt;&gt;&gt;&gt; 【<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/install/source#tested_build_configurations">TF CPU/GPU</a>】</p>
<p>[2] &gt;&gt;&gt;&gt; For Windows &gt;&gt;&gt;&gt; 【<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/install/source_windows#tested_build_configurations">TF CPU/GPU</a>】</p>
<hr>
<h3 id="关于服务器操作系统选择"><a href="#关于服务器操作系统选择" class="headerlink" title="关于服务器操作系统选择"></a>关于服务器操作系统选择</h3><p>关于搭建 TensorFlow 深度学习开发环境的服务器（Server）的操作系统的选择，选择一个合适的 OS 可以帮我们减少很多的麻烦。</p>
<p>👇👇👇 <strong>Centos/Ubuntu Server Select</strong> 👇👇👇</p>
<p><font color="red">| &gt;&gt;&gt;&gt; 1. Centos Server For Building TensorFlow</font> ↓↓↓↓↓↓↓</p>
<p>如果选择 Centos Server，那么我们的 Centos 版本最好选择 <code>Centos7</code>。<code>Centos6</code> 因为版本较低，其操作系统内置的库无法很好兼容 TensorFlow。虽可以解决，但会为安装带来更多的麻烦（可以通过升级一些运行时库得以解决）。</p>
<p>当然对于操作系统为 <code>Centos6</code> 的既有服务器，且不可以更换操作系统的安装需求，TF-CPU 中已经对解决方法做详细说明。</p>
<p><font color="red">| &gt;&gt;&gt;&gt; 2. Ubuntu Server For Building TensorFlow</font> ↓↓↓↓↓↓↓</p>
<p>如果选择 Ubuntu Server（<strong>墙裂推荐</strong>），那么我们的 Ubuntu 版本最好是 Ubuntu 14.04/16.04/18.04。这里只是因为使用 Ubuntu14.04/16.04/18.04 的人较多，可以更好的帮我们解决安装以及使用 TensorFlow 过程中遇到的问题。</p>
<blockquote>
<p>对于初学 TensorFlow 深度学习框架，仅仅想做做简单学习测试，强烈建议选择 Ubuntu！！！</p>
</blockquote>
<p>👇👇👇 <strong>Windows Platform</strong> 👇👇👇</p>
<p>一般情况下，Windows 平台下搭建 TensorFlow 深度学习框架仅作为简单学习使用，无法更高效利用软硬件资源。故，我们更应该关注基于 Liunx Server 搭建学习、开发环境。</p>
<hr>
<h3 id="Environment-Lists"><a href="#Environment-Lists" class="headerlink" title="Environment Lists"></a>Environment Lists</h3><p>基于以上，这里给出我的预安装环境准备：</p>
<p><strong>[1] &gt;&gt;&gt;&gt;</strong> 硬件环境说明</p>
<ul>
<li>搭载 Nvidia GeForce GTX 970 独立显卡联想 ThinkCentre 商业主机；</li>
<li>搭载 3TB 硬盘用于存储数据以及 32GB（4 * 8GB）内存条；</li>
<li>四核心 Inter CORE I7 CPU；</li>
<li>ThinkCentre 商用主机。</li>
</ul>
<p>–&gt; 联想 ThinkCentre 商用主机搭载 Nvidia GTX 970 独立显卡时问题：</p>
<ul>
<li>电源提供接口不够，购买电源转接线电源口 IDE 大 4D 芯一分二（4 pin公转母），显卡 6pin 转双大 4D。电源接线不够时，建议升级较大功率电源。</li>
<li>机箱主板空间较小无法安装索泰（ZOTAC）Nvidia GTX 970 独立显卡，购买 PCI-E 16X 显卡延长线。</li>
<li>购买 DVI 转 VGA24+5 Pin（显卡显示器高清视频转换接头）。</li>
</ul>
<p><strong>[2] &gt;&gt;&gt;&gt;</strong> 搭建环境说明</p>
<p><strong>Ubuntu16.04 + Nvidia GeForce GTX 970 + CUDA8.0 + CUDNN5.1  + Tensorflow1.2.0</strong></p>
<hr>
<p>从这里开始，正式开始【TensorFlow GPU Support】深度学习环境的配置：</p>
<h2 id="点亮-GPU-amp-amp-Ubuntu"><a href="#点亮-GPU-amp-amp-Ubuntu" class="headerlink" title="点亮 GPU &amp;&amp; Ubuntu"></a>点亮 GPU &amp;&amp; Ubuntu</h2><p>首先，毋庸置疑的是可以成功点亮 &gt;&gt;&gt;&gt; 搭载了 GPU 独立显卡的 Ubuntu 服务器。</p>
<p>关于服务器操作系统，我们选择安装的是：Ubuntu16.04，具体的安装过程不赘述，网上有很多。</p>
<p>这里，有个需要注意的地方（很重要）&gt;&gt;&gt;&gt; <font color="red">安装 Ubuntu16.04 系统时是否搭载（连接）GPU？！！</font></p>
<p>也就是说，这里我们有两种安装方式可供选择：</p>
<p><font color="red">第一种</font>：直接在主板上搭载 GPU，显示器接 GPU 输出接口，然后完成 Ubuntu16.04 系统的点亮；</p>
<p><font color="red">第二种</font>：不搭载 GPU（拔掉）安装好 Ubuntu16.04 系统（此时显示器接主机 VGA 接口），关机后安装好 GPU 并将显示器接 GPU 输出接口。</p>
<p>👇👇👇 <strong>重点来了</strong> 👇👇👇</p>
<p>通常使用的是第一种安装方式，但默认的前提是 Ubuntu16.04 安装引导系统能够正常识别 GPU（系统中默认显卡驱动支持该型号 GPU）。否则，你会发现：使用 U 盘启动盘安装系统时无法进入 Ubuntu 安装引导界面，怎么重启都没用。</p>
<p>而一旦拔掉 GPU，显示器转接主机 VGA 接口后，重启可成功进入安装引导界面（集显正常）。此时，你就需要考虑第二种方法了。</p>
<p>没看懂，不要着急~~~</p>
<hr>
<p>故，搭建 <strong>TensorFlow [GPU Support]</strong> 环境第一步就是要解决系统显卡驱动问题：</p>
<h3 id="显卡驱动"><a href="#显卡驱动" class="headerlink" title="显卡驱动"></a>显卡驱动</h3><p>根据安装 Ubuntu16.04 系统时是否搭载（连接）GPU，分为两种显卡驱动安装方式：</p>
<p>[1] &gt;&gt;&gt;&gt; <strong>搭载式安装</strong> &lt;&lt;&lt;&lt; 对应上述第一种安装方式</p>
<p>[2] &gt;&gt;&gt;&gt; <strong>非搭载式安装（推荐）</strong> &lt;&lt;&lt;&lt; 对应上述第二种安装方式</p>
<p>下面将针对上述两种安装方法，给出其显卡驱动安装的具体步骤。</p>
<hr>
<h4 id="查询系统显卡信息"><a href="#查询系统显卡信息" class="headerlink" title="查询系统显卡信息"></a>查询系统显卡信息</h4><p>首先，你需要查询当前系统显卡信息，以获取显卡详细信息，检查显卡驱动版本是否合适 CUDA 运算。具体检测过程如下：</p>
<p><strong>1 &gt;&gt;&gt;&gt; 搭载式安装（第一种）</strong></p>
<p>如果直接搭载 GPU 独显的服务器使用 U 盘启动安装 Ubuntu16.04，成功点亮了系统（显示器接 GPU 显示引导界面），那么恭喜你，当前系统默认显卡驱动支持你的 GPU。（<font color="red">如果无法成功，请移步至【2 &gt;&gt;&gt;&gt; 非搭载式安装（第二种) 】</font>）</p>
<p>成功点亮系统后，我们可以直接查询当前系统中 GPU 的详细信息：</p>
<p><strong>[1] &gt;&gt;&gt;&gt;</strong> 查询本机的显卡型号</p>
<p>因显卡一般接 PCI 接口，可以通过 <code>lspci</code> 查询显卡相关信息。一般我们可以查看到两种类型显卡：一块时集显；一块是独显。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lspci -vnn |grep VGA -A 12</span><br><span class="line">01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM206 [GeForce GTX 970] [10de:1401] (rev a1) (prog-if 00 [VGA controller])</span><br><span class="line">        Subsystem: ZOTAC International (MCO) Ltd. GM206 [GeForce GTX 970] [19da:1379]</span><br><span class="line">        Flags: bus master, fast devsel, latency 0, IRQ 124</span><br><span class="line">        Memory at f6000000 (32-bit, non-prefetchable) [size=16M]</span><br><span class="line">        Memory at e0000000 (64-bit, prefetchable) [size=256M]</span><br><span class="line">        Memory at f0000000 (64-bit, prefetchable) [size=32M]</span><br><span class="line">        I/O ports at e000 [size=128]</span><br><span class="line">        Expansion ROM at 000c0000 [disabled] [size=128K]</span><br><span class="line">        Capabilities: [60] Power Management version 3</span><br><span class="line">        Capabilities: [68] MSI: Enable+ Count=1/1 Maskable- 64bit+</span><br><span class="line">        Capabilities: [78] Express Legacy Endpoint, MSI 00</span><br><span class="line">        Capabilities: [100] Virtual Channel</span><br><span class="line">        Capabilities: [258] L1 PM Substates</span><br></pre></td></tr></table></figure>

<p>| ================================= <strong>↓↓↓↓↓ 显卡信息 ↓↓↓↓↓</strong> ============================== |</p>
<p>独立显卡： 硬件厂商 NAVIDA（N卡）；型号名称 GM206（GeForce GTX 970）</p>
<p>集成显卡：这里由于直接是搭载 GPU 的服务器安装系统，无法查看到集显信息</p>
<p>| ================================================================================ |</p>
<p><strong>[2] &gt;&gt;&gt;&gt;</strong> 确认本机显卡驱动是否正常加载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lshw -C display</span><br><span class="line">  *-display</span><br><span class="line">       description: VGA compatible controller</span><br><span class="line">       product: GM206 [GeForce GTX 970]</span><br><span class="line">       vendor: NVIDIA Corporation</span><br><span class="line">       physical id: 0</span><br><span class="line">       bus info: pci@0000:01:00.0</span><br><span class="line">       version: a1</span><br><span class="line">       width: 64 bits</span><br><span class="line">       clock: 33MHz</span><br><span class="line">       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom</span><br><span class="line">       configuration: driver=nouveau latency=0</span><br><span class="line">       resources: irq:124 memory:f6000000-f6ffffff memory:e0000000-efffffff memory:f0000000-f1ffffff ioport:e000(size=128) memory:c0000-dffff</span><br></pre></td></tr></table></figure>

<p>输出信息 <code>configuration</code> 字段中，如果 <code>driver=“驱动名称”</code> 不为空，说明系统支持该显卡的驱动。</p>
<p>我们可以看出，Ubuntu 系统支持 GTX 970 显卡且自动安装有一个默认的显卡驱动：<code>nouveau</code>（Linux 开源的显卡驱动）。</p>
<p>事实上，<code>nouveau</code>  驱动开发是很不完善的，我们需要重新安装适合显卡的（这里是 GTX960） Nvidia 显卡驱动才可以正常使用 TensorFlow 深度学习显卡加速。</p>
<p>到这里，你可以直接跳转到【Nvidia 显卡驱动安装】小节，接着完成后续的过程。</p>
<hr>
<p><strong>2 &gt;&gt;&gt;&gt; 非搭载式安装（第二种）</strong></p>
<p>如果你采用第一种直接搭载 GPU 独显的服务器使用 U 盘启动安装 Ubuntu16.04，发现：无法进入 Ubuntu 安装引导界面，怎么重启都没用。而一旦拔掉 GPU，显示器转接主机 VGA 接口后，重启可成功进入安装引导界面。</p>
<p>此时，我们首先需要先拔掉 GPU，后将显示器转接主机 VGA 接口，安装 Ubuntu16.04。</p>
<p>成功点亮系统后，我们可以查询当前系统中 GPU（集显）的详细信息：</p>
<p><strong>[1] &gt;&gt;&gt;&gt;</strong> 查询本机的显卡型号</p>
<p>因显卡一般是 PCI 接口，可以通过 <code>lspci</code> 查询显卡相关信息。一般我们可以查看到两种类型显卡：一块时集显；一块是独显。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">deeplearning@ThinkCentre-M910s-N000:~$ lspci -vnn|grep VGA -A 12</span><br><span class="line">00:02.0 VGA compatible controller [0300]: Intel Corporation HD Graphics 630 [8086:5912] (rev 04) (prog-if 00 [VGA controller])</span><br><span class="line">    DeviceName:  Onboard IGD</span><br><span class="line">    Subsystem: Lenovo Device [17aa:3107]</span><br><span class="line">    Flags: bus master, fast devsel, latency 0, IRQ 124</span><br><span class="line">    Memory at f6000000 (64-bit, non-prefetchable) [size=16M]</span><br><span class="line">    Memory at e0000000 (64-bit, prefetchable) [size=256M]</span><br><span class="line">    I/O ports at f000 [size=64]</span><br><span class="line">    [virtual] Expansion ROM at 000c0000 [disabled] [size=128K]</span><br><span class="line">    Capabilities: &lt;access denied&gt;</span><br><span class="line">    Kernel driver in use: i915</span><br><span class="line">    Kernel modules: i915</span><br></pre></td></tr></table></figure>

<p>这里只能查询到一块集显（未搭载独显）：</p>
<p>| ================================= <strong>↓↓↓↓↓ 显卡信息 ↓↓↓↓↓</strong> ============================== |</p>
<p>集成显卡: 硬件厂商 Intel，型号名称 Corporation HD Graphics 630</p>
<p>| ================================================================================ |</p>
<p><strong>[2] &gt;&gt;&gt;&gt;</strong> 确认本机显卡驱动是否正常加载</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">deeplearning@ThinkCentre-M910s-N000:~$ sudo lshw -C display</span><br><span class="line">[sudo] password for deeplearning: </span><br><span class="line">  *-display               </span><br><span class="line">       description: VGA compatible controller</span><br><span class="line">       product: HD Graphics 630</span><br><span class="line">       vendor: Intel Corporation</span><br><span class="line">       physical id: 2</span><br><span class="line">       bus info: pci@0000:00:02.0</span><br><span class="line">       version: 04</span><br><span class="line">       width: 64 bits</span><br><span class="line">       clock: 33MHz</span><br><span class="line">       capabilities: pciexpress msi pm vga_controller bus_master cap_list rom</span><br><span class="line">       configuration: driver=i915 latency=0</span><br><span class="line">       resources: irq:124 memory:f6000000-f6ffffff memory:e0000000-efffffff ioport:f000(size=64) memory:c0000-dffff</span><br></pre></td></tr></table></figure>

<p>输出信息 <code>configuration</code> 字段中，如果 <code>driver=“i915”</code> 不为空，系统中集显驱动为：“i915”。</p>
<p>此时，先不要着急关机搭载 GPU！！！（如果你尝试关机后搭载 GPU，并将显示器接 GPU 输出接口同样会发现无法进入安装引导界面（系统中默认显卡驱动是不支持该型号 GPU的），故无法正常输出信号到显示器）。</p>
<p><font color="red"> ↓↓↓↓↓↓ 解决办法 ↓↓↓↓↓↓</font></p>
<p>我们需要在安装好的系统中安装一个支持该型号 GPU 的先看驱动，接下文【Nvidia 显卡驱动安装】。</p>
<hr>
<h4 id="Nvidia-显卡驱动安装"><a href="#Nvidia-显卡驱动安装" class="headerlink" title="Nvidia 显卡驱动安装"></a>Nvidia 显卡驱动安装</h4><p>下面我们来看，如何为特定型号的 GPU 安装合适版本的 Nvidia 显卡驱动：</p>
<p><strong>1 &gt;&gt;&gt;&gt; 查询适合的 Nvidia 驱动</strong></p>
<p>首先打开以及登陆 &gt;&gt;&gt; <a target="_blank" rel="noopener" href="http://www.nvidia.com/Download/index.aspx?lang=en-us">Nvidia Driver 官网</a> &lt;&lt;&lt; 根据独立显卡型号查询适合自己显卡的驱动（以 GTX 980 Ti 为例）：</p>
<p><img src="https://s2.loli.net/2023/04/02/mxd8tSh7gwKqp3r.png"></p>
<p>点击 <code>SEARCH</code>，查询显卡驱动信息：</p>
<p><img src="https://s2.loli.net/2023/04/02/Y1FzqJ4eNxuQTBG.png"></p>
<hr>
<p><strong>2 &gt;&gt;&gt;&gt; 安装 Nvidia 驱动</strong></p>
<p>查询到适用的 Nvidia 驱动版本后，开始安装 Nvidia 驱动 <code>390.25</code>：</p>
<p><strong>[1] &gt;&gt;&gt;&gt;</strong> 使用 PPA 安装</p>
<p><font color="red">↓↓↓↓↓↓ 1. 首先需要添加 ppa 仓库 ↓↓↓↓↓↓</font></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure>

<p>第一次运行会出现如下的警告：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Fresh drivers from upstream, currently shipping Nvidia.</span><br><span class="line"></span><br><span class="line"><span class="comment">## Current Status</span></span><br><span class="line">We currently recommend: `nvidia-361`, Nvidia<span class="string">&#x27;s current long lived branch.</span></span><br><span class="line"><span class="string">For GeForce 8 and 9 series GPUs use `nvidia-340`</span></span><br><span class="line"><span class="string">For GeForce 6 and 7 series GPUs use `nvidia-304`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## What we&#x27;</span>re working on right now:</span><br><span class="line">- Normal driver updates</span><br><span class="line">- Investigating how to bring this goodness to distro on a cadence.</span><br><span class="line">- </span><br><span class="line"><span class="comment">## WARNINGS:</span></span><br><span class="line">This PPA is currently <span class="keyword">in</span> testing, you should be experienced with packaging before you dive <span class="keyword">in</span> here. Give us a few days to sort out the kinks.</span><br><span class="line">Volunteers welcome! See also: https://github.com/mamarley/nvidia-graphics-drivers/</span><br><span class="line"></span><br><span class="line">http://www.ubuntu.com/download/desktop/contribute</span><br><span class="line">更多信息： https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa</span><br><span class="line">按回车继续或者 Ctrl+c 取消添加</span><br></pre></td></tr></table></figure>

<p>–&gt;【Enter】后继续：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Enter 后显示如下信息表示添加成功：</span></span><br><span class="line">gpg: keyring `/tmp/tmp7b1tsfut/secring.gpg<span class="string">&#x27; created</span></span><br><span class="line"><span class="string">gpg: keyring `/tmp/tmp7b1tsfut/pubring.gpg&#x27;</span> created</span><br><span class="line">gpg: requesting key 1118213C from hkp server keyserver.ubuntu.com</span><br><span class="line">gpg: /tmp/tmp7b1tsfut/trustdb.gpg: trustdb created</span><br><span class="line">gpg: key 1118213C: public key <span class="string">&quot;Launchpad PPA for Graphics Drivers Team&quot;</span> imported</span><br><span class="line">gpg: no ultimately trusted keys found</span><br><span class="line">gpg: Total number processed: 1</span><br><span class="line">gpg:               imported: 1  (RSA: 1)</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>| ================================= <strong>↓↓↓↓↓ 添加 PPA 仓库报错 ↓↓↓↓↓</strong> ============================== |</p>
<p>如果添加 PPA 仓库报错的话，可以先 <code>remove</code> 掉，然后重新尝试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo add-apt-repository --remove ppa:graphics-drivers/ppa</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo add-apt-repository ppa:graphics-drivers/ppa</span></span><br></pre></td></tr></table></figure>

<p>| ======================================================================================== |</p>
<p><font color="red">↓↓↓↓↓↓ 2. 更新本地 apt-get 源 ↓↓↓↓↓↓</font></p>
<p>添加完 PPA 仓库，需要更新一下本地 apt-get 源，以检测添加的 PPA 仓库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure>

<p><font color="red">↓↓↓↓↓↓ 3. 识别显卡模型和查看源中推荐的驱动程序 ↓↓↓↓↓↓</font></p>
<p>添加 PPA 仓库并且更新源后，先来识别显卡模型和查看源中推荐的驱动程序（<strong>如果采用非搭载式安装的话跳过</strong>）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ubuntu-drivers devices</span><br><span class="line">== /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 ==</span><br><span class="line">modalias : pci:v000010DEd00001401sv000019DAsd00001379bc03sc00i00</span><br><span class="line">model    : GM206 [GeForce GTX 970]</span><br><span class="line">vendor   : NVIDIA Corporation</span><br><span class="line">driver   : nvidia-415 - third-party free</span><br><span class="line">driver   : nvidia-384 - distro non-free</span><br><span class="line">driver   : nvidia-396 - third-party free</span><br><span class="line">driver   : nvidia-418 - third-party free</span><br><span class="line">driver   : nvidia-410 - third-party free</span><br><span class="line">driver   : xserver-xorg-video-nouveau - distro free <span class="built_in">builtin</span></span><br><span class="line">driver   : nvidia-390 - third-party free</span><br><span class="line">driver   : nvidia-430 - third-party free recommended</span><br></pre></td></tr></table></figure>

<p>为什么采用非搭载式安装的话跳过这里？？？非搭载式没有 GPU，查询无效，可直接选择【1 &gt;&gt;&gt;&gt; 查询适合的 Nvidia 驱动】中查询到的显卡驱动版本。</p>
<p><font color="red">↓↓↓↓↓↓ 4. 安装源中推荐的驱动程序 ↓↓↓↓↓↓</font></p>
<p>首先你可以看到，PAA 仓库中提供有我们之前查询到的 <code>390</code> 版本的 Nvidia 驱动，你可以安装此版本。</p>
<p>当然，你也可以根据源中推荐的 Nvidia 版本进行安装（Recommended）。这里我的 GPU 为：<code>GTX 970</code>，故选择了 <code>nvidia-384</code>，它是支持 GTX 970 的一个稳定版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install nvidia-384</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装一些可能的依赖插件：</span></span><br><span class="line">$ sudo apt-get install mesa-common-dev</span><br><span class="line">$ sudo apt-get install freeglut3-dev</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>推荐阅读：</strong> 安装 Nvidia 驱动还有其它方法，但推荐使用 PPA 仓库安装 Nvidia 驱动，这是最简单的驱动安装方式。关于使用官方的驱动进行手动安装这里就不介绍了。</p>
</blockquote>
<p><strong>[2] &gt;&gt;&gt;&gt;</strong> 使显卡驱动生效</p>
<p>针对搭载式安装，直接重启：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo reboot</span><br></pre></td></tr></table></figure>

<p>如果采用非搭载式安装的话，上述驱动安装完成后，直接关机，然后搭载 GPU 并将显示器接 GPU 输出接口，便可发现已经可以进入系统了。</p>
<p>| =============================================== <strong>Split Line</strong> ================================================== |</p>
<p>安装好显卡驱动后就可以进行驱动测试了：</p>
<p><strong>[3] &gt;&gt;&gt;&gt;</strong> 确认安装的显卡驱动是否正常加载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lshw -C display</span><br><span class="line">  *-display</span><br><span class="line">       description: VGA compatible controller</span><br><span class="line">       product: GM206 [GeForce GTX 970]</span><br><span class="line">       vendor: NVIDIA Corporation</span><br><span class="line">       physical id: 0</span><br><span class="line">       bus info: pci@0000:01:00.0</span><br><span class="line">       version: a1</span><br><span class="line">       width: 64 bits</span><br><span class="line">       clock: 33MHz</span><br><span class="line">       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom</span><br><span class="line">       configuration: driver=nvidia latency=0</span><br><span class="line">       resources: irq:127 memory:f6000000-f6ffffff memory:e0000000-efffffff memory:f0000000-f1ffffff ioport:e000(size=128) memory:c0000-dffff</span><br></pre></td></tr></table></figure>

<p>可以发现，<code>driver=nvidia</code> 表明安装成功。</p>
<p><strong>[4] &gt;&gt;&gt;&gt;</strong> 查看显卡运行状态</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ watch -n -1 nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示如下信息表示显卡驱动安装成功（Ctrl + c 可退出查看状态）： </span></span><br><span class="line"></span><br><span class="line">Sat Jun  2 17:03:40 2018       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 384.130                Driver Version: 384.130                   |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  GeForce GTX 970     Off  | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">| 36%   45C    P8    11W / 120W |   3863MiB /  4036MiB |      3%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0      1143      G   /usr/lib/xorg/Xorg                            94MiB |</span><br><span class="line">|    0      2070      G   compiz                                        42MiB |</span><br><span class="line">|    0     18635      G   /usr/lib/firefox/firefox                       1MiB |</span><br><span class="line">|    0     29337      C   ...naconda3/envs/tensorflow-3.5/bin/python  3710MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Nvidia-驱动升级"><a href="#Nvidia-驱动升级" class="headerlink" title="Nvidia 驱动升级"></a>Nvidia 驱动升级</h4><p>对于已经安装了 <code>Nvidia</code> 显卡驱动的服务器，但其驱动版本过低。或者前面安装了不合适的  <code>Nvidia</code> 显卡驱动，无法正常使用新版本的 CUDA。</p>
<p>故，我们一般会将 <code>Nvidia</code> 显卡驱动更新到一个较新的版本。</p>
<p>前面我们已经知道如何安装全新的 <code>Nvidia</code> 显卡驱动，这里来看如何快速卸载服务器原有的显卡驱动程序：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get --purge remove nvidia*</span><br></pre></td></tr></table></figure>

<p>上述我们已经卸载了系统中的 Nvidia 显卡驱动，注意 &gt;&gt;&gt;&gt; <strong>此时千万不能重启，重新电脑可能会导致无法进入系统，安装好新驱动后再重启！</strong></p>
<p>接下来我们需要根据章节【Nvidia 驱动驱动安装】完成新的 <code>Nvidia</code> 显卡驱动的安装。</p>
<hr>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>好奇么？驱动安装不是都已经结束了，怎么还有一小节？？？黑脸？！！、</p>
<p>–&gt; 总结一下：</p>
<p>前面我们知道了如何基于搭载 GPU 独显的服务器安装 Ubuntu16.04 ，然后安装适合版本的显卡驱动（搭载式）。</p>
<p>另外，我们还同时说明了非搭载式安装方法：先把 GPU 拿掉，然后在只有集显的服务器上先安装 Ubuntu16.04 ，接着按照章节【Nvidia 驱动驱动安装】安装 Nvidia 显卡驱动，然后 <code>shutdown</code> 关机安装上 GPU 后重启即可。</p>
<p>事实上，非搭载式安装方法可以帮助我们避免驱动安装中的很多麻烦。</p>
<hr>
<p>👇👇👇 <strong>部署 CUDA &amp;&amp; cuDNN</strong> 👇👇👇</p>
<p>在开始 CUDA 和 cuDNN 的部署之前，你需要通过查看 <font color="green">Tensorflow &amp;&amp; NVIDIA 版本信息对照表 &gt;&gt;&gt; 见【CUDA &amp;&amp; CUDNN &amp;&amp; TF】中说明</font>，选择和预安装和 TensorFlow [GPU Support] 版本兼容的 CUDA &amp;&amp; cuDNN 版本。</p>
<p>版本清单 &gt;&gt;&gt;&gt; <code>TensorFlow v1.2.0 &amp;&amp; CUDA Toolkit v8.0 &amp;&amp; CuDNN v5.1</code>。</p>
<h2 id="部署-CUDA-8-0"><a href="#部署-CUDA-8-0" class="headerlink" title="部署 CUDA 8.0"></a>部署 CUDA 8.0</h2><p>我选择使用的 TensorFlow 版本是：TensorFlow-gpu-1.2.0，所以需要安装 <strong>CUDA 8.0</strong>。</p>
<p>在安装 CUDA 之前，Google 了一下，发现在 Ubuntu 下安装 CUDA 8.0 非常常见，支持 GTX 970。</p>
<p>下面我们将以 CUDA 8.0 的安装为样例（其它版本 CUDA 安装类似）：</p>
<h3 id="环境检测"><a href="#环境检测" class="headerlink" title="环境检测"></a>环境检测</h3><p>安装 CUDA 8.0 之前，请先确认系统中是否已安装有默认的 CUDA 版本？！！执行如下命令查看系统 CUDA 版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ nvcc -V</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下信息表示当前系统已安装有 CUDA，安装目录见：/usr/local/</span></span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2016 NVIDIA Corporation</span><br><span class="line">Built on Tue_Jan_10_13:22:03_CST_2017</span><br><span class="line">Cuda compilation tools, release 8.0, V8.0.61</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没有的话输出如下：</span></span><br><span class="line">The program <span class="string">&#x27;nvcc&#x27;</span> is currently not installed. You can install it by typing:</span><br><span class="line">sudo apt install nvidia-cuda-toolkit</span><br></pre></td></tr></table></figure>

<p>如果有，可以跳转至【CUDA 卸载】章节，先卸载掉系统中已安装的 CUDA 版本，再开始下面的步骤。</p>
<hr>
<h3 id="Download-CUDA"><a href="#Download-CUDA" class="headerlink" title="Download CUDA"></a>Download CUDA</h3><p>下载 CUDA 需要注册和登陆 NVIDIA 开发者账号，CUDA8 下载页面提供了很详细的系统选择和安装说明。</p>
<p>这里，我们首先提供 &gt;&gt;&gt; 【<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-80-ga2-download-archive">CUDA 8.0 下载地址</a>】，并且选择做如下平台设置（其它版本戳 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">这里</a>）:</p>
<div align=center><img src="https://s2.loli.net/2023/04/02/dwj1zT6emRhNLDQ.png"></div>

<p>这里选择了 Ubuntu16.04 系统 <code>Runfile</code> 安装方案，千万不要选择 deb 方案，否则前方无数坑。</p>
<p>配置好平台设置后，进入下载界面。如下：</p>
<div align=center><img src="https://s2.loli.net/2023/04/02/2avlsfpF3nkPBeG.png"></div>

<p>这里，只需下载 <code>cuda_8.0.27_linux.run</code>(1.4GB) 即可。</p>
<hr>
<p>下载好的 <code>cuda_8.0.27_linux.run</code> 有 <code>1.4G</code>。下面按照 Nvidia 官方给出的方法安装 CUDA8：</p>
<h3 id="Setup-CUDA"><a href="#Setup-CUDA" class="headerlink" title="Setup CUDA"></a>Setup CUDA</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sh cuda_8.0.27_linux.run --tmpdir=/opt/temp/</span><br></pre></td></tr></table></figure>

<p>这里加了 <code>--tmpdir</code> 主要是因为直接运行 <code>sudo sh cuda_8.0.27_linux.run</code> 可能会提示空间不足的错误（如下）。实际上是全新的电脑主机，硬盘足够大的（当报错后，你知道如何解决即可）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Not enough space on parition mounted at /.</span><br><span class="line">Need 5091561472 bytes.</span><br><span class="line"></span><br><span class="line">Disk space check has failed. Installation cannot <span class="built_in">continue</span>.</span><br></pre></td></tr></table></figure>

<p><strong>–&gt; 执行 <code>sh cuda_8.0.27_linux.run</code> 后会有一系列提示让你确认，非常非常非常关键的地方是是否安装 <code>361</code> 这个低版本的驱动：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 361.62 ?</span><br></pre></td></tr></table></figure>

<p>答案必须是 <code>n</code>，否则之前为 GTX960 安装的  <code>nvidia-384</code> 驱动就白费了，而且后续问题多多。</p>
<p>👇👇👇 <strong>详细安装步骤如下</strong> 👇👇👇</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">Logging to /opt/temp//cuda_install_6583.log</span><br><span class="line">Using more to view the EULA.</span><br><span class="line">End User License Agreement</span><br><span class="line">--------------------------</span><br><span class="line">Preface</span><br><span class="line">-------</span><br><span class="line">The following contains specific license terms and conditions</span><br><span class="line"><span class="keyword">for</span> four separate NVIDIA products. By accepting this</span><br><span class="line">agreement, you agree to comply with all the terms and</span><br><span class="line">conditions applicable to the specific product(s) included</span><br><span class="line">herein.</span><br><span class="line"></span><br><span class="line">Do you accept the previously <span class="built_in">read</span> EULA?</span><br><span class="line">accept/decline/quit: accept</span><br><span class="line"></span><br><span class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 361.62?</span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line"></span><br><span class="line">Install the CUDA 8.0 Toolkit?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line">Enter Toolkit Location</span><br><span class="line">[ default is /usr/<span class="built_in">local</span>/cuda-8.0 ]:</span><br><span class="line"></span><br><span class="line">Do you want to install a symbolic link at /usr/<span class="built_in">local</span>/cuda?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line">Install the CUDA 8.0 Samples?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line">Enter CUDA Samples Location</span><br><span class="line">[ default is /home/textminer ]:</span><br><span class="line"></span><br><span class="line">Driver: Not Selected</span><br><span class="line"></span><br><span class="line">Installing the CUDA Toolkit <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0 ...</span><br><span class="line">Installing the CUDA Samples <span class="keyword">in</span> /home/textminer ...</span><br><span class="line">Copying samples to /home/textminer/NVIDIA_CUDA-8.0_Samples now...</span><br><span class="line">Finished copying samples.</span><br><span class="line"></span><br><span class="line">===========</span><br><span class="line">= Summary =</span><br><span class="line">===========</span><br><span class="line"></span><br><span class="line">Driver: Not Selected</span><br><span class="line">Toolkit: Installed <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0</span><br><span class="line">Samples: Installed <span class="keyword">in</span> /home/textminer</span><br><span class="line"></span><br><span class="line">Please make sure that</span><br><span class="line">- PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/bin</span><br><span class="line">- LD_LIBRARY_PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/lib64, or, add /usr/<span class="built_in">local</span>/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</span><br><span class="line"></span><br><span class="line">To uninstall the CUDA Toolkit, run the uninstall script <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/bin</span><br><span class="line"></span><br><span class="line">Please see CUDA_Installation_Guide_Linux.pdf <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/doc/pdf <span class="keyword">for</span> detailed information on setting up CUDA.</span><br><span class="line"></span><br><span class="line">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required <span class="keyword">for</span> CUDA 8.0 functionality to work.</span><br><span class="line">To install the driver using this installer, run the following <span class="built_in">command</span>, replacing with the name of this run file:</span><br><span class="line">sudo .run -silent -driver</span><br><span class="line"></span><br><span class="line">Logfile is /opt/temp//cuda_install_6583.log</span><br></pre></td></tr></table></figure>

<p>安装完成之后，不要清空终端！不要清空终端！不要清空终端！后面有用处。</p>
<p>👇👇👇 <strong>配置环境变量</strong> 👇👇👇</p>
<p>安装完毕后，需要再声明一下环境变量，并将其写入到 <code>~/.bashrc</code> 的尾部:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-8.0/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-8.0/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>

<p>更新 <code>~/.bashrc</code> 配置文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：如果是已经安装了 NVIDIA 和 CUDA 的云服务器环境，还需要添加环境变量才可以使用。</p>
</blockquote>
<p>| =============================================== <strong>Split Line</strong> ================================================== |</p>
<p>如果环境变量设置错误，导致 系统<code>PATH</code> 值被覆盖了，这会导致 <code>ls、make</code> 等基本命令都用不了，提示 <code>xxx: command not found</code>。后来查阅资料，通过输入以下语句，可还原 <code>PATH</code> 变量值进行恢复（恢复至默认 <code>PATH</code> 值）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin</span><br></pre></td></tr></table></figure>

<hr>
<p>至此，CUDA8.0 的部署其实已经完成了！！！但是请注意安装过程中这里可能有报错（<code>missing recommended</code>）：</p>
<p>👇👇👇 <strong>Problem：Missing Recommended</strong> 👇👇👇</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Driver: Not Selected</span><br><span class="line">Toolkit: Installed <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0</span><br><span class="line">Samples: Installed <span class="keyword">in</span> /home/textminer, but missing recommended</span><br></pre></td></tr></table></figure>

<p>知道上面为什么不清空终端了吧~~~</p>
<p>不会报错，不注意的话，会导致后续 <code>CUDA</code> 测试（ <code>nbody</code> 样例），如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span>  ~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody  </span><br><span class="line">$ make </span><br><span class="line">$ ./nbody</span><br></pre></td></tr></table></figure>

<p>即在 CUDA 上运行 <code>nbody</code> 样例，<code>make</code> 部分发生报错：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; WARNING - libGLU.so not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - libX11.so not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - gl.h not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - glu.h not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - Xlib.h not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=<span class="literal">true</span> -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o bodysystemcuda.o -c bodysystemcuda.cu</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=<span class="literal">true</span> -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o nbody.o -c nbody.cpp</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=<span class="literal">true</span> -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o render_particles.o -c render_particles.cpp</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o nbody bodysystemcuda.o nbody.o render_particles.o -L/usr/lib/nvidia-367 -lGL -lGLU -lX11 -lglut</span><br><span class="line">[@] mkdir -p ../../bin/x86_64/linux/release</span><br><span class="line">[@] cp nbody ../../bin/x86_64/linux/release</span><br></pre></td></tr></table></figure>

<p><font color="red"> ↓↓↓↓↓↓ 解决方案 ↓↓↓↓↓↓ </font></p>
<p>从 <code>make</code> 报错信息中得知，缺少了一些编译库，下面我们来安装这些库文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa libglu1-mesa-dev libglfw3-dev libgles2-mesa-dev</span><br><span class="line"></span><br><span class="line">$ GLPATH=/usr/lib make</span><br></pre></td></tr></table></figure>

<p><strong>–&gt; 成功之后会显示：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; Windowed mode</span><br><span class="line">&gt; Simulation data stored <span class="keyword">in</span> video memory</span><br><span class="line">&gt; Single precision floating point simulation</span><br><span class="line">&gt; 1 Devices used <span class="keyword">for</span> simulation</span><br><span class="line">gpuDeviceInit() CUDA Device [0]: <span class="string">&quot;GeForce GTX 970</span></span><br><span class="line"><span class="string">&gt; Compute 6.1 CUDA device: [GeForce GTX 1080]</span></span><br><span class="line"><span class="string">number of bodies = 256000</span></span><br><span class="line"><span class="string">256000 bodies, total time for 10 iterations: 2291.469 ms</span></span><br><span class="line"><span class="string">= 286.000 billion interactions per second</span></span><br><span class="line"><span class="string">= 5719.998 single-precision GFLOP/s at 20 flops per interaction</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Test-CUDA"><a href="#Test-CUDA" class="headerlink" title="Test CUDA"></a>Test CUDA</h3><p><strong>[1] &gt;&gt;&gt;&gt;</strong> 输出 CUDA 版本信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> nvcc –V</span></span><br></pre></td></tr></table></figure>

<p>信息显示如下：</p>
<div align=center><img src="https://s2.loli.net/2023/04/02/dEUTc5KYfqop7ZB.png"></div>

<p><strong>[2] &gt;&gt;&gt;&gt;</strong> 查询 GPU 信息</p>
<p>–&gt; 进入 <code>cd NVIDIA_CUDA-8.0_Sample/1_Utilities/deviceQuery</code> 目录：</p>
<p>–&gt; 执行：<code>make</code>；</p>
<p>–&gt; 执行：<code>./deviceQuery</code></p>
<p>结果如下：</p>
<div align=center><img src="https://s2.loli.net/2023/04/02/BQp9SZYzCXIHlv4.png"></div>

<p><strong>[3] &gt;&gt;&gt;&gt;</strong> nbody 测试</p>
<p>nbody 测试见【Problem：Missing Recommended】中相关说明。</p>
<p>恭喜你~~~~ 至此，CUDA 部署已经完成！！！</p>
<hr>
<h3 id="Remove-CUDA"><a href="#Remove-CUDA" class="headerlink" title="Remove CUDA"></a>Remove CUDA</h3><p>通过前面的介绍，我们了解了如何在服务器上安装 CUDA 应用。事实上，很多时候我们的服务器本身已经默认安装了某个版本的 CUDA，而搭建 <code>TensorFlow For GPU Support</code> 环境要求安装特定版本的 CUDA。</p>
<blockquote>
<p>如果你无法确认系统中是否存在使用当前版本 CUDA 的应用时，不推荐卸载，为了尽量降低对原始系统的影响，你可以跳转至【<strong>CUDA 多版本管理</strong>】来解决问题。</p>
</blockquote>
<p>↓↓↓↓↓↓ 对于有卸载需求的，我们来看如何卸载服务器中已安装的 CUDA ↓↓↓↓↓↓</p>
<p>分别针对 <code>.deb</code> 和 <code>.run</code> 两种不同的安装方式（卸载方法不同），这里提供两种方式来卸载系统原有的 CUDA：</p>
<p><strong>[1] &gt;&gt;&gt;&gt;</strong> .run 方法卸载</p>
<p>执行如下命令进行自动卸载（以 <code>cuda-8.0</code> 卸载为例）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo /usr/<span class="built_in">local</span>/cuda-8.0/bin/uninstall_cuda-8.0.pl</span></span><br></pre></td></tr></table></figure>

<p>有上述卸载文件 <code>uninstall_cuda-8.0.pl</code> 就说明是之前是用 <code>.run</code> 文件安装的，没有则是用 <code>.deb</code> 文件安装的，可以使用第二种方法进行卸载：</p>
<p><strong>[2] &gt;&gt;&gt;&gt;</strong> .deb 方法卸载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get remove cuda</span><br><span class="line"></span><br><span class="line">$ sudo apt-get autoclean</span><br><span class="line"></span><br><span class="line">$ sudo apt-get remove cuda*</span><br></pre></td></tr></table></figure>

<p><font color="red"> ↓↓↓↓↓↓ 清空残留文件 ↓↓↓↓↓↓ </font></p>
<p>最后，将当前目录切换至 <code>/usr/local/</code> 下，查看是否还残留有未删除干净的 CUDA 相关文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">$ ls</span><br><span class="line"></span><br><span class="line">% 存在残留文件则删除：</span><br><span class="line">sudo rm -rf cuda-8.0</span><br></pre></td></tr></table></figure>

<hr>
<p>接着来看 CUDNN 的下载与安装：</p>
<h2 id="部署-CUDNN-5-1"><a href="#部署-CUDNN-5-1" class="headerlink" title="部署 CUDNN 5.1"></a>部署 CUDNN 5.1</h2><p>CUDNN 全称 <code>CUDA Deep Neural Network library</code>，是 NVIDIA 专门针对深度神经网络设计的一套 GPU 计算加速库，被广泛用于各种深度学习框架，例如 <code>Caffe, TensorFlow, Theano, Pytorch, CNTK</code> 等。</p>
<h3 id="Download-CuDNN"><a href="#Download-CuDNN" class="headerlink" title="Download CuDNN"></a>Download CuDNN</h3><p>从 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cudnn">Nvidia 官方 CuDNN 地址</a> 下载链接选择一个期望版本，不过下载 cuDNN 前同样需要注册登录甚至填写一个简单的调查问卷，链接界面如下：</p>
<p><img src="https://s2.loli.net/2023/04/02/2X6bkeIilrGawN3.png"></p>
<p>从中你可以选择适合操作系统的 CUDNN 计算加速库。</p>
<hr>
<h3 id="Setup-CuDNN"><a href="#Setup-CuDNN" class="headerlink" title="Setup CuDNN"></a>Setup CuDNN</h3><p>安装 CuDNN 比较简单，解压后把相应的文件拷贝到对应的 CUDA 目录下即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf cudnn-8.0-linux-x64-v5.1.tgz</span><br><span class="line"></span><br><span class="line">cuda/include/cudnn.h</span><br><span class="line">cuda/lib64/libcudnn.so</span><br><span class="line">cuda/lib64/libcudnn.so.5</span><br><span class="line">cuda/lib64/libcudnn.so.5.0.5</span><br><span class="line">cuda/lib64/libcudnn_static.a</span><br><span class="line"></span><br><span class="line">$ sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include/</span><br><span class="line">$ sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64/</span><br><span class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h</span><br><span class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>

<p>可以发现，cuDNN 中的 5 个文件（全部），在 <code>/usr/local/cuda/include/ &amp;&amp; /usr/local/cuda/lib64/</code> 中找不到相同文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /usr/<span class="built_in">local</span>/cuda/lib64/ |grep libcudnn</span><br><span class="line">$ ls /usr/<span class="built_in">local</span>/cuda/include/ |grep cudnn</span><br></pre></td></tr></table></figure>

<p>也就意味着：CuDNN 其实就是 CUDA 的扩展计算库，把 cuDNN 相关库文件添加 CUDA 里，不会对 CUDA 造成其他影响，即所谓的 <strong>插入式设计</strong>。这保证了当前系统环境中可以存在多个版本的 cuDNN。</p>
<hr>
<p>CuDNN 的插入式设计 &gt;&gt;&gt;&gt; 帮助我们简单、快捷的实现 CuDNN 的升级或多版本管理：</p>
<h3 id="Update-CuDNN"><a href="#Update-CuDNN" class="headerlink" title="Update CuDNN"></a>Update CuDNN</h3><p>这里，假设一下：上面我们已经完成了 <code>cuDNN v5.1 for CUDA8.0</code> 的安装。事实上，我们需要的是 <code>cuDNN v6.0 for CUDA8.0</code> 计算加速包，那么我们如何将 <code>cuDNN</code> 版本升级到 <code>cuDNN v6.0</code> 呢？？？</p>
<p>其实很简单。下载 <code>cuDNN v6.0</code> 安装包 <code>cudnn-8.0-linux-x64-v6.0.tgz</code>、解压以及使用 <code>cuDNN v6.0</code> 库文件覆盖 <code>CUDA</code> 中的 <code>cuDNN v5.1</code> 库文件即可。详细步骤如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> tar -zxvf cudnn-8.0-linux-x64-v6.0.tgz</span></span><br><span class="line"></span><br><span class="line">cuda/include/cudnn.h</span><br><span class="line">cuda/lib64/libcudnn.so</span><br><span class="line">cuda/lib64/libcudnn.so.6</span><br><span class="line">cuda/lib64/libcudnn.so.6.0.6</span><br><span class="line">cuda/lib64/libcudnn_static.a</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> rm /usr/<span class="built_in">local</span>/cuda/include/cudnn.h</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> rm /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span></span><br></pre></td></tr></table></figure>

<hr>
<p>至此，CUDA 8.0 以及 CUDNN 5.1 安装完成！！！接下来就可以开始 Tensorflow GPU Enabled 的安装了。</p>
<h2 id="部署-TensorFlow-GPU"><a href="#部署-TensorFlow-GPU" class="headerlink" title="部署 TensorFlow-GPU"></a>部署 TensorFlow-GPU</h2><p>这里，我们使用 Anaconda 的方式来部署 TensorFlow-GPU 深度学习环境。</p>
<p><strong>1 &gt;&gt;&gt;&gt; Conda Envs install TensorFlow</strong></p>
<p>通过 Anaconda 安装 Tensorflow 详细过程参见博文 &gt;&gt;&gt; <a href="https://www.orangeshare.cn/2018/04/01/yi-wen-xiang-jie-quan-ping-tai-tensorflow-shen-du-xue-xi-kuang-jia-zai-xian-da-jian-cpu-gpu-zhi-chi/#TensorFlow-GPU-%E6%94%AF%E6%8C%81/">一文详解全平台 TensorFlow 深度学习框架在线搭建 (CPU&amp;GPU 支持)</a> &lt;&lt;&lt; 【使用 Anaconda 安装】小节，篇幅原因不赘述。</p>
<p>对于其它方式的 TensorFlow 部署，可以参见博文中的其它章节。</p>
<p><strong>2 &gt;&gt;&gt;&gt; TensorFlow 导入测试</strong></p>
<p>正常情况，如果安装的 Python、TensorFlow、CUDA 、CUDNN 版本正确，<code>import tensorflow as tf</code> 时，无报错。</p>
<p>| ========================= <strong>↓↓↓↓↓ CUDA &amp; CUDNN 与不相容版本的 TensorFlow 问题 ↓↓↓↓↓</strong> ========================= |</p>
<p>以安装 <code>tensorflow-gpu1.3</code> 为例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libcudnn.so.6:cannot open sharedobjectfile:No such file or directory</span><br></pre></td></tr></table></figure>

<p>根据错误代码，应该是找不到 <code>libcudnn.so.6</code>。</p>
<p>到指定文件夹下发现只有 <code>5.0</code> 和 <code>8.0</code> 的版本，没有 <code>6.0</code>，查找原因是因为当前已经是 <code>1.3</code> 版本，而 <code>tensorflow-gpu1.3</code> 已经开始去找 <code>cudnn6</code> 了（也就是说是用 <code>cudnn6</code> 编译的）… </p>
<p>故，需要换到 <code>tensorflow-gpu1.2</code> 版本，就解决问题了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 先卸载掉之前安装的错误版本的 TensorFlow 环境，然后重新安装 ：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip uninstall tensorflow-gpu==1.3</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install tensorflow-gpu==1.2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">或者</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 直接移除整个 conda 虚拟环境，然后重新安装：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda remove –n tensorflow-3.5 –all</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> conda create –n tensorflow-3.5 python=3.5</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">source</span> activate tensorflow-3.5</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install tensorflow-gpu==1.2</span></span><br></pre></td></tr></table></figure>

<p>| ================================================================================================== |</p>
<hr>
<p><strong>3 &gt;&gt;&gt;&gt; GPU 运算测试</strong></p>
<p>这里以一个简单的向量加法为例来测试 TensorFlow [GPU Support] 环境，测试代码如下（<code>gpu_test.py</code>）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>], shape=[<span class="number">3</span>], name=”a”)</span><br><span class="line">b = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>], shape=[<span class="number">3</span>], name=”b”)</span><br><span class="line">result = a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 log_device_placement 参数来输出运行每一个运算的设备：</span></span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (sess.run(result))</span><br></pre></td></tr></table></figure>

<p>结果输出信息如下：</p>
<p>[3.1] &gt;&gt;&gt;&gt; 在没有 GPU 的机器上运行上述代码，可以得到如下输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Device mapping: no known devices</span><br><span class="line">add :/job:localhost/replica:0/task:0/cpu:0</span><br><span class="line">a : /job:localhost/replica:0/task:0/cpu:0</span><br><span class="line">b : /job:localhost/replica:0/task:0/cpu:0</span><br></pre></td></tr></table></figure>

<p>[3.2] 配置好 GPU 环境的 TensorFlow 中，没有明确制定运行设备的话，TensorFlow 会优先选择 GPU 设备运行，会得到如下结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0</span><br><span class="line">2018-02-04 13:01:33.343286: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0</span><br><span class="line"></span><br><span class="line">add: (Add): /job:localhost/replica:0/task:0/gpu:0</span><br><span class="line">2018-02-04 13:01:33.343948: I tensorflow/core/common_runtime/simple_placer.cc:847] add: (Add)/job:localhost/replica:0/task:0/gpu:0</span><br><span class="line">b: (Const): /job:localhost/replica:0/task:0/gpu:0</span><br><span class="line">2018-02-04 13:01:33.343980: I tensorflow/core/common_runtime/simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/gpu:0</span><br><span class="line">a: (Const): /job:localhost/replica:0/task:0/gpu:0</span><br><span class="line">2018-02-04 13:01:33.343997: I tensorflow/core/common_runtime/simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/gpu:0</span><br><span class="line">[2. 4. 6.]</span><br></pre></td></tr></table></figure>

<p>自此，我们就完成了 <strong>Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN + Anaconda3 + Tensorflow1.2</strong> 深度学习环境搭建。</p>
<hr>
<h2 id="You-Need-Know-More"><a href="#You-Need-Know-More" class="headerlink" title="You Need Know More"></a>You Need Know More</h2><p>扩展阅读部分：</p>
<h3 id="NVIDIA-显卡相关"><a href="#NVIDIA-显卡相关" class="headerlink" title="NVIDIA 显卡相关"></a>NVIDIA 显卡相关</h3><p><strong>[1] &gt;&gt;&gt;&gt;</strong> nvidia-smi</p>
<p>英伟达系统管理接口（<code>NVIDIA System Management Interface</code>, 简称 <code>nvidia-smi</code>），属于命令行管理组件，旨在帮助管理和监控 <code>NVIDIA GPU</code> 设备。</p>
<p>执行 <code>nvidia-smi</code> 命令可以查看当前系统安装的 NVIDIA 驱动信息以及 GPU 使用情况，显示如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> root@Ubuntu:~<span class="comment"># nvidia-smi</span></span></span><br><span class="line"></span><br><span class="line">Thu Feb 28 15:50:39 2019       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla P4            On   | 00000000:00:07.0 Off |                    0 |</span><br><span class="line">| N/A   30C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<p>可以看出：驱动版本（NVIDIA-SMI 390.46）、显卡型号（Tesla P4）、内存（7611MiB：8G）以及 GPU 使用率（GPU-Util  Compute M.： 0% Default）等。</p>
<p><code>nvidia-smi</code> 配合 <code>watch -n</code> 一起使用，可用于查看 <code>GPU</code> 的实时动态使用情况：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> watch -n -1 nvidia-smi</span> </span><br></pre></td></tr></table></figure>

<p><strong>[2] &gt;&gt;&gt;&gt;</strong> lspci</p>
<p>查看服务器集成显卡信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> lspci | grep VGA</span></span><br><span class="line">00:02.0 VGA compatible controller: Cirrus Logic GD 5446</span><br></pre></td></tr></table></figure>

<p>查看服务器 NVIDIA 显卡信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ lspci | grep NVIDIA</span><br><span class="line">00:07.0 3D controller: NVIDIA Corporation Device 1bb3 (rev a1)</span><br></pre></td></tr></table></figure>

<p><strong>[3] &gt;&gt;&gt;&gt;</strong> 集显与独显的切换</p>
<p>NVIDIA 还提供了用于切换显卡的命令。例如，查看当前使用的显卡：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo prime-select query</span></span><br></pre></td></tr></table></figure>

<p>如何切换 nvidia 显卡：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo prime-select nvidia</span></span><br></pre></td></tr></table></figure>

<p>如何切换 intel 显卡：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo prime-select intel</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="CUDA-多版本管理"><a href="#CUDA-多版本管理" class="headerlink" title="CUDA 多版本管理"></a>CUDA 多版本管理</h3><p>事实上，很多情况下我们需要多个 CUDA 版本兼容存在于服务器系统中，并且可以很容易地在不同版本之间进行迅速切换。</p>
<p>请参见如下场景：</p>
<p><strong>场景一</strong> &gt;&gt;&gt; 多人共享使用当前服务器，由于使用的 TensorFlow 框架版本不同，所需要的 CUDA 版本也不同。此时，系统需要存在多个版本的 CUDA。</p>
<p><strong>场景二</strong> &gt;&gt;&gt; 之前搭建 TensorFlow 环境使用的是 <code>CUDA8.0</code> 和 <code>cuDNN5.1</code>，当我们需要在 TensorFlow 环境中兼容其它深度学习环境时（比如搭建 <code>TensorFlow + Pytorch</code> 环境），<code>Pytroch GPU Support</code> 可能需要更高版本的 <code>CUDA</code> 以及 <code>cuDNN</code>。此时，升级 <code>CUDA</code> 以及 <code>cuDNN</code> 版本以适应 <code>TensorFlow + Pytorch</code> 环境是必要的。</p>
<p>怎么办？？？卸载重装？？？</p>
<hr>
<p>这一章节，我们会以同时部署 <code>cuda-8.0</code> 和 <code>cuda-9.0</code> 版本为例进行说明：</p>
<h4 id="CUDA-多版本共存"><a href="#CUDA-多版本共存" class="headerlink" title="CUDA 多版本共存"></a>CUDA 多版本共存</h4><p>对于 <code>cuda-8.0</code> 和 <code>cuda-9.0</code>，无论先安装哪个版本，都一样。</p>
<p>上面已经安装过 <code>cuda-8.0</code> 了，这里，我们将扩展安装 <code>cuda-9.0</code> 版本：</p>
<p><strong>1 &gt;&gt;&gt;&gt; Download &amp;&amp; Setup CUDA9.0</strong></p>
<p>下载 CUDA 需要注册和登陆 NVIDIA 开发者账号。这里，我们首先给出 &gt;&gt;&gt; <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA 版本库地址</a> &lt;&lt;&lt; 供选择下载期望版本的 CUDA 安装包，版本库页面如下：</p>
<p><img src="https://s2.loli.net/2023/04/02/n9oMAYvPcugHUKk.png"></p>
<p>通过 CUDA 版本库地址进入 CUDA9.0 下载页面：</p>
<p><img src="https://s2.loli.net/2023/04/02/TYJGrdqMLfxcI83.png"></p>
<p>可以看到这里提供了很详细的系统选择和安装说明，这里选择了 <code>Ubuntu16.04</code> 系统 <code>Runfile</code> 安装方案（千万不要选择 <code>deb</code> 方案，否则前方无数坑）。</p>
<p>下载完成之后，进入到 CUDA9.0 安装包（<code>cuda_9.0.176_384.81_linux.run</code>）所在目录运行如下命令即可开始进行安装，详细安装过程讲解如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo sh cuda_9.0.176_384.81_linux.run</span></span><br><span class="line"></span><br><span class="line">Using more to view the EULA.</span><br><span class="line">End User License Agreement</span><br><span class="line">--------------------------</span><br><span class="line">Preface</span><br><span class="line">-------</span><br><span class="line">The following contains specific license terms and conditions</span><br><span class="line">for four separate NVIDIA products. By accepting this</span><br><span class="line">agreement, you agree to comply with all the terms and</span><br><span class="line">conditions applicable to the specific product(s) included</span><br><span class="line">herein.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 接受安装协议：</span></span><br><span class="line">Do you accept the previously read EULA?</span><br><span class="line">accept/decline/quit: accept</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 询问是否重新安装显卡驱动，这里一定要选择 `n`，否则最初安装的显卡驱动会被覆盖产生出错：</span></span><br><span class="line">Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?</span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line"></span><br><span class="line">Install the CUDA 9.0 Toolkit?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义安装目录（一般默认回车即可，即安装在 `/usr/<span class="built_in">local</span>/cuda-9.0` 目录下）,</span></span><br><span class="line">Enter Toolkit Location</span><br><span class="line">[ default is /usr/local/cuda-9.0 ]: </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 询问是否将 `cuda-9.0` 安装目录通过软连接的方式 link 到 `/usr/<span class="built_in">local</span>/cuda`？【 yes or no 】 均可。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 系统当前启用的 `cuda` 为哪个版本？取决于哪个版本的 CUDA 安装目录被链接到 `/usr/<span class="built_in">local</span>/cuda` 上。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 对于首次安装 CUDA，肯定是需要建立软连接的（yes）；对于安装额外版本的 CUDA，【 yes or no 】 需要根据是否启动新版本 CUDA 决定。</span></span><br><span class="line">Do you want to install a symbolic link at /usr/local/cuda? </span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 询问是否安装样例，可用于后续检测是否安装成功：</span></span><br><span class="line">Install the CUDA 9.0 Samples?</span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义样例安装目录：</span></span><br><span class="line">Enter CUDA Samples Location</span><br><span class="line">[ default is /root ]: /home/textminer</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> *** 安装信息显示 **** <span class="comment">#</span></span></span><br><span class="line">Driver: Not Selected</span><br><span class="line"></span><br><span class="line">Installing the CUDA Toolkit in /usr/local/cuda-9.0 ...</span><br><span class="line">Installing the CUDA Samples in /home/textminer ...</span><br><span class="line">Copying samples to /home/textminer/NVIDIA_CUDA-9.0_Samples now...</span><br><span class="line">Finished copying samples.</span><br><span class="line"></span><br><span class="line">===========</span><br><span class="line">= Summary =</span><br><span class="line">===========</span><br><span class="line"></span><br><span class="line">Driver: Not Selected</span><br><span class="line">Toolkit: Installed in /usr/local/cuda-9.0</span><br><span class="line">Samples: Installed in /home/textminer</span><br><span class="line"></span><br><span class="line">Please make sure that</span><br><span class="line">- PATH includes /usr/local/cuda-9.0/bin</span><br><span class="line">- LD_LIBRARY_PATH includes /usr/local/cuda-9.0/lib64, or, add /usr/local/cuda-9.0/lib64 to /etc/ld.so.conf and run ldconfig as root</span><br><span class="line"></span><br><span class="line">To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin</span><br><span class="line"></span><br><span class="line">Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-9.0/doc/pdf for detailed information on setting up CUDA.</span><br><span class="line"></span><br><span class="line">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 9.0 functionality to work.</span><br><span class="line">To install the driver using this installer, run the following command, replacing with the name of this run file:</span><br><span class="line">sudo .run -silent -driver</span><br><span class="line"></span><br><span class="line">Logfile is /opt/temp//cuda_install_6583.log</span><br></pre></td></tr></table></figure>

<p>安装过程中是否创建 <code>symbolic link</code> 是关键。首次安装，选【yes】；安装额外的版本，选【no】。</p>
<hr>
<p><strong>2 &gt;&gt;&gt;&gt; 配置 CUDA 环境变量</strong></p>
<p>在当前用户配置文件 <code>~/.bashrc</code> 末尾添加如下内容：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64</span><br><span class="line">export PATH=$PATH:/usr/local/cuda/bin</span><br><span class="line">export CUDA_HOME=$CUDA_HOME:/usr/local/cuda</span><br></pre></td></tr></table></figure>

<p>需要注意的是，这里配置的 CUDA 目录并不是特指 CUDA9.0 的安装目录，而是一个特殊的 CUDA 目录（不管 CUDA8.0/9.0/…）。这样做的好处你可以参见下一小节【CUDA 版本实时切换】。</p>
<p>自此，我们已经成功完成了 <code>cuda-8.0</code> 和 <code>cuda-9.0</code> 的安装。</p>
<hr>
<p>下面我们来看如何迅速完成 CUDA 版本的切换：</p>
<h4 id="CUDA-版本实时切换"><a href="#CUDA-版本实时切换" class="headerlink" title="CUDA 版本实时切换"></a>CUDA 版本实时切换</h4><p>通过上文可知，当我们安装了多个版本的 CUDA 之后，CUDA 一般会被安装到 <code>/usr/local/</code> 目录（或你自己的自定义目录）下。查看一下当前目录下的文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /usr/<span class="built_in">local</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line">bin  cuda  cuda-8.0  cuda-9.0 etc  games ......</span><br></pre></td></tr></table></figure>

<p>上述 <code>cuda-8.0</code> 和 <code>cuda-9.0</code> 是系统中已安装的 CUDA 版本，而 <code>cuda</code> 就是我们上面创建的 <code>symbolic link</code>。</p>
<blockquote>
<p><code>cuda</code> 指向系统当前正在启用的 CUDA 版本 &gt;&gt;&gt; 方便了我们切换 CUDA 版本，可以让我们不用每次都去 <code>~/.bashrc</code> 修改环境变量的值（<code>cuda-8.0/-9.0/...</code>）。</p>
</blockquote>
<p>我们先来查看当前 <code>cuda</code> 软链接指向的哪个 <code>cuda</code> 版本:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">stat</span> cuda</span></span><br><span class="line">  File: &#x27;cuda&#x27; -&gt; &#x27;/usr/local/cuda-8.0&#x27;</span><br><span class="line">  Size: 19        	Blocks: 0          IO Block: 4096   symbolic link</span><br><span class="line">Device: 807h/2055d	Inode: 133904      Links: 1</span><br><span class="line">Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Access: 2019-02-28 10:44:36.494902702 +0800</span><br><span class="line">Modify: 2018-02-03 10:52:47.543432671 +0800</span><br><span class="line">Change: 2018-02-03 10:52:47.543432671 +0800</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure>

<p>可以看到，<code>cuda&#39; -&gt; &#39;/usr/local/cuda-8.0</code>，此时系统当前正在启用的 CUDA 版本为 <code>cuda-8.0</code>。</p>
<p>那么，我们如何快速完成 <code>cuda-9.0</code> 的版本呢？其实很简单：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 查看系统当前启用的 CUDA 版本：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> nvcc -V</span></span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2016 NVIDIA Corporation</span><br><span class="line">Built on Tue_Jan_10_13:22:03_CST_2017</span><br><span class="line">Cuda compilation tools, release 8.0, V8.0.61</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 从 `cuda8.0` 切换到 `cuda9.0`:</span> </span><br><span class="line"><span class="meta">$</span><span class="bash"> rm -rf /usr/<span class="built_in">local</span>/cuda</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo ln -s /usr/<span class="built_in">local</span>/cuda-9.0/ /usr/<span class="built_in">local</span>/cuda/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看切换后的CUDA 版本：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> nvcc --version</span></span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2016 NVIDIA Corporation</span><br><span class="line">Built on Tue_Jan_10_13:22:03_CST_2018</span><br><span class="line">Cuda compilation tools, release 9.0, V9.0.176</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="CUDNN-多版本管理"><a href="#CUDNN-多版本管理" class="headerlink" title="CUDNN 多版本管理"></a>CUDNN 多版本管理</h3><p>事实上，关于 CUDNN 多版本共存和实时切换的问题，在【部署 CUDNN 5.1】章节中 &gt;&gt;&gt;&gt; 【Update CuDNN】小节以及解决，请参考上文。</p>
<hr>
</div><div class="article-licensing box"><div class="licensing-title"><p>TensorFlow GPU 支持: Ubuntu16.04 + Nvidia GTX + CUDA + CUDNN</p><p><a href="https://www.orangeshare.cn/2018/04/02/tensorflow-gpu-zhi-chi-ubuntu16-04-nvidia-gtx-cuda-cudnn/">https://www.orangeshare.cn/2018/04/02/tensorflow-gpu-zhi-chi-ubuntu16-04-nvidia-gtx-cuda-cudnn/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Waldeinsamkeit</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2018-04-02</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-04-03</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/TensorFlow/">TensorFlow</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2018/04/03/tensorflow-ru-men-zhi-tf-ji-ben-gong-zuo-yuan-li/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">TensorFlow 入门之 TF 基本工作原理</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/04/01/libstdc-so-6-version-cxxabi-1-3-x-not-found/"><span class="level-item">Libstdc++.so.6 Version &#039;CXXABI_1.3.X&#039; Not Found</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen  order-3 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Waldeinsamkeit"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Waldeinsamkeit</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">100</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">13</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">43</p></a></div></div></nav></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Before-Reading"><span class="level-left"><span class="level-item">1</span><span class="level-item">Before Reading</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#服务器硬件要求"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">服务器硬件要求</span></span></a></li><li><a class="level is-mobile" href="#你应该了解你的-GPU"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">你应该了解你的 GPU</span></span></a></li><li><a class="level is-mobile" href="#CUDA-amp-amp-CUDNN-amp-amp-TF"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">CUDA &amp;&amp; CUDNN &amp;&amp; TF</span></span></a></li><li><a class="level is-mobile" href="#关于服务器操作系统选择"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">关于服务器操作系统选择</span></span></a></li><li><a class="level is-mobile" href="#Environment-Lists"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">Environment Lists</span></span></a></li></ul></li><li><a class="level is-mobile" href="#点亮-GPU-amp-amp-Ubuntu"><span class="level-left"><span class="level-item">2</span><span class="level-item">点亮 GPU &amp;&amp; Ubuntu</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#显卡驱动"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">显卡驱动</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#查询系统显卡信息"><span class="level-left"><span class="level-item">2.1.1</span><span class="level-item">查询系统显卡信息</span></span></a></li><li><a class="level is-mobile" href="#Nvidia-显卡驱动安装"><span class="level-left"><span class="level-item">2.1.2</span><span class="level-item">Nvidia 显卡驱动安装</span></span></a></li><li><a class="level is-mobile" href="#Nvidia-驱动升级"><span class="level-left"><span class="level-item">2.1.3</span><span class="level-item">Nvidia 驱动升级</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Summary"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Summary</span></span></a></li></ul></li><li><a class="level is-mobile" href="#部署-CUDA-8-0"><span class="level-left"><span class="level-item">3</span><span class="level-item">部署 CUDA 8.0</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#环境检测"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">环境检测</span></span></a></li><li><a class="level is-mobile" href="#Download-CUDA"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Download CUDA</span></span></a></li><li><a class="level is-mobile" href="#Setup-CUDA"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">Setup CUDA</span></span></a></li><li><a class="level is-mobile" href="#Test-CUDA"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">Test CUDA</span></span></a></li><li><a class="level is-mobile" href="#Remove-CUDA"><span class="level-left"><span class="level-item">3.5</span><span class="level-item">Remove CUDA</span></span></a></li></ul></li><li><a class="level is-mobile" href="#部署-CUDNN-5-1"><span class="level-left"><span class="level-item">4</span><span class="level-item">部署 CUDNN 5.1</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Download-CuDNN"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Download CuDNN</span></span></a></li><li><a class="level is-mobile" href="#Setup-CuDNN"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Setup CuDNN</span></span></a></li><li><a class="level is-mobile" href="#Update-CuDNN"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Update CuDNN</span></span></a></li></ul></li><li><a class="level is-mobile" href="#部署-TensorFlow-GPU"><span class="level-left"><span class="level-item">5</span><span class="level-item">部署 TensorFlow-GPU</span></span></a></li><li><a class="level is-mobile" href="#You-Need-Know-More"><span class="level-left"><span class="level-item">6</span><span class="level-item">You Need Know More</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#NVIDIA-显卡相关"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">NVIDIA 显卡相关</span></span></a></li><li><a class="level is-mobile" href="#CUDA-多版本管理"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">CUDA 多版本管理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#CUDA-多版本共存"><span class="level-left"><span class="level-item">6.2.1</span><span class="level-item">CUDA 多版本共存</span></span></a></li><li><a class="level is-mobile" href="#CUDA-版本实时切换"><span class="level-left"><span class="level-item">6.2.2</span><span class="level-item">CUDA 版本实时切换</span></span></a></li></ul></li><li><a class="level is-mobile" href="#CUDNN-多版本管理"><span class="level-left"><span class="level-item">6.3</span><span class="level-item">CUDNN 多版本管理</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="When Art Meets Tech" height="28"></a><p class="is-size-7"><span>&copy; 2023 Waldeinsamkeit</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>